{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akin-oladejo/scenes/blob/main/instance_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# --- Configuration ---\n",
        "# You can change this path to your own video file (e.g., 'my_test_video.mp4').\n",
        "# Use '0' to capture from the default webcam.\n",
        "VIDEO_SOURCE = '0'\n",
        "MODEL_PATH = 'yolov8n-seg.pt'  # Smallest and fastest model for real-time\n",
        "CONFIDENCE_THRESHOLD = 0.4    # Minimum confidence to consider a detection\n",
        "OUTPUT_FILENAME = 'segmented_output.mp4'\n",
        "\n",
        "def get_person_masks(frame_source=VIDEO_SOURCE, model_path=MODEL_PATH):\n",
        "    \"\"\"\n",
        "    Main function to run YOLOv8-Seg instance segmentation on a video stream or file.\n",
        "\n",
        "    This implementation manually extracts and colors the segmentation masks\n",
        "    for the 'person' class (class ID 0) to ensure clear, distinct visualization.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Task 1: YOLOv8 Model Initialization ---\n",
        "    try:\n",
        "        model = YOLO(model_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        print(\"Please ensure the model file path is correct and ultralytics is installed.\")\n",
        "        return\n",
        "\n",
        "    # --- Task 2: Basic Video Processing Pipeline Setup ---\n",
        "    # Convert '0' (string) to 0 (int) for webcam\n",
        "    source = int(frame_source) if frame_source.isdigit() else frame_source\n",
        "    cap = cv2.VideoCapture(source)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not open video source {frame_source}.\")\n",
        "        return\n",
        "\n",
        "    # Get frame properties for video writing\n",
        "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    FPS = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # --- Task 5: Initialize Video Writer ---\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Codec for MP4\n",
        "    writer = cv2.VideoWriter(OUTPUT_FILENAME, fourcc, FPS, (W, H))\n",
        "\n",
        "    # Variables for FPS calculation\n",
        "    frame_count = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(f\"--- Starting Segmentation ({'Webcam' if source == 0 else source}) ---\")\n",
        "    print(f\"Outputting to: {OUTPUT_FILENAME}\")\n",
        "\n",
        "    # --- Main Processing Loop ---\n",
        "    while cap.isOpened():\n",
        "        success, frame = cap.read()\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "        # --- Task 3: YOLOv8 Inference ---\n",
        "        # Run prediction, only targeting class 0 (person)\n",
        "        # We run it on the CPU by default, change 'cpu' to 'cuda' if you have GPU setup\n",
        "        results = model(frame, conf=CONFIDENCE_THRESHOLD, classes=[0], verbose=False, device='cpu')\n",
        "        res = results[0]\n",
        "\n",
        "        # Initialize a blank color overlay for blending\n",
        "        # We need a copy of the frame as a float array to handle blending properly\n",
        "        processed_frame = frame.astype(np.float32)\n",
        "\n",
        "        # --- Task 4: Mask Extraction and Processing ---\n",
        "        if res.masks is not None:\n",
        "\n",
        "            # The Ultralytics mask data is a tensor of low-resolution masks\n",
        "            masks_data = res.masks.data.cpu().numpy()\n",
        "\n",
        "            # Iterate through each detected mask (which are all people due to classes=[0])\n",
        "            for i, mask_tensor in enumerate(masks_data):\n",
        "\n",
        "                # 1. Resize mask to original frame dimensions (H, W)\n",
        "                mask = cv2.resize(\n",
        "                    mask_tensor,\n",
        "                    (W, H),\n",
        "                    interpolation=cv2.INTER_NEAREST\n",
        "                ).astype(bool)\n",
        "\n",
        "                # 2. Create a unique color for the current person\n",
        "                # We use fixed, bright colors for good distinction.\n",
        "                # In a real application, you might use a HASH function on person ID for consistency.\n",
        "                color_map = [\n",
        "                    (0, 255, 255),  # Cyan\n",
        "                    (255, 0, 255),  # Magenta\n",
        "                    (255, 255, 0),  # Yellow\n",
        "                    (0, 255, 0),    # Green\n",
        "                    (0, 0, 255),    # Blue\n",
        "                    (255, 0, 0),    # Red\n",
        "                ]\n",
        "                # Cycle through colors based on the index\n",
        "                person_color = color_map[i % len(color_map)]\n",
        "\n",
        "                # 3. Create a color overlay (a colored patch where the mask is True)\n",
        "                color_patch = np.zeros_like(frame, dtype=np.uint8)\n",
        "                color_patch[mask] = person_color\n",
        "\n",
        "                # 4. Blend the color patch with the original frame for a smooth, visible mask\n",
        "                # We use a 40% opacity for the color and 60% for the original frame\n",
        "                processed_frame[mask] = cv2.addWeighted(\n",
        "                    processed_frame[mask],\n",
        "                    0.6,\n",
        "                    color_patch[mask].astype(np.float32),\n",
        "                    0.4,\n",
        "                    0\n",
        "                )\n",
        "\n",
        "        # Convert back to uint8 for visualization\n",
        "        processed_frame_uint8 = processed_frame.astype(np.uint8)\n",
        "\n",
        "        # --- Task 5: Visualization and FPS Calculation ---\n",
        "\n",
        "        # Calculate FPS every 10 frames\n",
        "        if frame_count % 10 == 0:\n",
        "            end_time = time.time()\n",
        "            elapsed_time = end_time - start_time\n",
        "            current_fps = frame_count / elapsed_time\n",
        "            fps_text = f\"FPS: {current_fps:.2f}\"\n",
        "\n",
        "            # Display FPS on the frame\n",
        "            cv2.putText(processed_frame_uint8, fps_text, (10, 30),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "        # Display the processed frame\n",
        "        cv2.imshow('YOLOv8 Instance Segmentation', processed_frame_uint8)\n",
        "\n",
        "        # Write the processed frame to the output file\n",
        "        writer.write(processed_frame_uint8)\n",
        "\n",
        "        # Exit condition: press 'q'\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    # --- Cleanup ---\n",
        "    cap.release()\n",
        "    writer.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    print(f\"\\n--- Segmentation Finished ---\")\n",
        "    print(f\"Output saved to: {OUTPUT_FILENAME}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    get_person_masks()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "TiMhzCHaqDWO"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}